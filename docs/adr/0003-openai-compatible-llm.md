# ADR-0003: OpenAI-compatible client for summaries

**Status:** Accepted  
**Date:** 2026-02-08  
**Deciders:** Implementation + plan

## Context

Summaries are generated by an LLM. Need to support local (Ollama) and remote (OpenAI, Anyscale, etc.) without changing code per provider.

## Decision

Use an **OpenAI-compatible** HTTP client and env config (`OPENAI_BASE_URL`, `OPENAI_API_KEY`). One `complete(system_prompt, user_content)` function; prompt logic in code, not in DB.

## Consequences

- Positive: Works with Ollama, OpenAI, Mistral, etc.; minimal code path.
- Negative: Provider-specific quirks (e.g. response format) handled in one place.
- Follow-ups: Document env in README.

## Links

- Plan: section 3 (Tool selection)
- Scratch: docs/scratch/SCRATCH.md#4-summarizer
